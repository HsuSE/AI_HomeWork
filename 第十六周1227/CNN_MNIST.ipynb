{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train.reshape(-1, 28, 28, 1), x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model(ac='sigmoid'):\n",
    "    \n",
    "    cnn = Sequential()\n",
    "    \n",
    "    cnn.add(Conv2D(32, [5, 5], input_shape=(28, 28, 1), activation=ac, padding='same', name='Conv2d_5x5_1'))\n",
    "\n",
    "    cnn.add(Conv2D(64, [3, 3], activation=ac, padding='same', name='Conv2d_3x3_1'))\n",
    "    cnn.add(MaxPooling2D([3, 3], name='maxpool_1'))\n",
    "\n",
    "    cnn.add(Conv2D(128, [3, 3], activation=ac, padding='same', name='Conv2d_3x3_2'))\n",
    "    cnn.add(MaxPooling2D([2, 2], name='maxpool_2'))\n",
    "\n",
    "    cnn.add(Conv2D(128, [3, 3], activation=ac, padding='valid', name='Conv2d_3x3_3'))\n",
    "\n",
    "    cnn.add(Flatten())\n",
    "    cnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation compare:\n",
      "\tSigmoid vs ReLU\n",
      "\n",
      "Activation Use sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2d_5x5_1 (Conv2D)        (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "Conv2d_3x3_1 (Conv2D)        (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "maxpool_1 (MaxPooling2D)     (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "Conv2d_3x3_2 (Conv2D)        (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "maxpool_2 (MaxPooling2D)     (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv2d_3x3_3 (Conv2D)        (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 245,898\n",
      "Trainable params: 245,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/30\n",
      "43072/54000 [======================>.......] - ETA: 31s - loss: 2.3095 - acc: 0.1099"
     ]
    }
   ],
   "source": [
    "activations = ['sigmoid', 'relu']\n",
    "ac_logger = []\n",
    "print(\"Activation compare:\")\n",
    "print(\"\\tSigmoid vs ReLU\\n\")\n",
    "for activation in activations:\n",
    "    print(\"Activation Use\", activation)\n",
    "    model = CNN_model(ac=activation)\n",
    "    model.compile(optimizer='sgd',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    callback = EarlyStopping(monitor='acc', min_delta=0.001, patience=5)\n",
    "    ac_logger.append(model.fit(x_train, y_train, epochs=30, validation_split=0.1, callbacks=[callback]))\n",
    "    eva = model.evaluate(x_test, y_test)\n",
    "    print(\"Test accuracy: %.2f loss: %.2f\" % (eva[1]*100, eva[0]))\n",
    "    \n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ['r', 'b']\n",
    "label_n = []\n",
    "for idx, log in enumerate(ac_logger):\n",
    "    label_n.append(activations[idx]+' acc')\n",
    "    label_n.append(activations[idx]+' val_acc')\n",
    "    plt.plot(log.history['acc'], '{}-.'.format(color[idx]))\n",
    "    plt.plot(log.history['val_acc'], '{}--'.format(color[idx]))\n",
    "\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(label_n, loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "label_n = []\n",
    "for idx, log in enumerate(ac_logger):\n",
    "    label_n.append(activations[idx]+' loss')\n",
    "    label_n.append(activations[idx]+' val_loss')\n",
    "    plt.plot(log.history['loss'], '{}-.'.format(color[idx]))\n",
    "    plt.plot(log.history['val_loss'], '{}--'.format(color[idx]))\n",
    "\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(label_n, loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'relu'\n",
    "bs_logger = []\n",
    "\n",
    "Batch_Sizes = [32, 64, 128, 256]\n",
    "print(\"Batch Size compare:\")\n",
    "print(\"\\tSigmoid vs ReLU\\n\")\n",
    "for batch_size in Batch_Sizes:\n",
    "    print(\"Batch Size\", batch_size)\n",
    "    model = CNN_model(ac=activation)\n",
    "    model.compile(optimizer='sgd',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    callback = EarlyStopping(monitor='acc', min_delta=0.001, patience=5)\n",
    "    bs_logger.append(model.fit(x_train, y_train, batch_size=batch_size, epochs=30, validation_split=0.1, callbacks=[callback]))\n",
    "    eva = model.evaluate(x_test, y_test)\n",
    "    print(\"Test accuracy: {%.2f} loss: {%.2f}\" % (eva[1]*100, eva[0]))\n",
    "    \n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ['r', 'b', 'g', 'y']\n",
    "label_n = []\n",
    "\n",
    "for idx, log in enumerate(bs_logger):\n",
    "    label_n.append(Batch_Sizes[idx]+'batch acc')\n",
    "    label_n.append(Batch_Sizes[idx]+'batch val_acc')\n",
    "    plt.plot(log.history['acc'], '{}.'.format(color[idx]))\n",
    "    plt.plot(log.history['val_acc'], '{}-'.format(color[idx]))\n",
    "\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(label_n, loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "label_n = []\n",
    "for idx, log in enumerate(logger):\n",
    "    label_n.append(Batch_Sizes[idx]+'batch loss')\n",
    "    label_n.append(Batch_Sizes[idx]+'batch val_loss')\n",
    "    plt.plot(log.history['loss'], '{}.'.format(color[idx]))\n",
    "    plt.plot(log.history['val_loss'], '{}-'.format(color[idx]))\n",
    "\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(label_n, loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "activation = 'relu'\n",
    "opt_logger = []\n",
    "\n",
    "lr = 0.01\n",
    "sgd = SGD(lr, momentum=0.0)\n",
    "sgd_momentum  = SGD(lr, momentum=0.05)\n",
    "rmsprop = RMSprop(lr)\n",
    "adam = Adam(lr)\n",
    "\n",
    "optimizers = [sgd, sgd_momentum, rmsprop, adam]\n",
    "\n",
    "print(\"Optimizer compare:\")\n",
    "for opt in optimizers:\n",
    "    print(\"Activation Use\", activation)\n",
    "    model = CNN_model(ac=activation)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    callback = EarlyStopping(monitor='acc', min_delta=0.001, patience=5)\n",
    "    opt_logger.append(model.fit(x_train, y_train, epochs=30, validation_split=0.1, callbacks=[callback]))\n",
    "    print(\"Test accuracy: {%.2f} loss: {%.2f}\" % (eva[1]*100, eva[0]))\n",
    "\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ['r', 'b', 'g', 'y']\n",
    "opt_name = ['SGD', 'SGD + Momentum', 'RMSprop', 'Adam']\n",
    "label_n = []\n",
    "\n",
    "for idx, log in enumerate(opt_logger):\n",
    "    label_n.append(opt_name[idx]+' acc')\n",
    "    label_n.append(opt_name[idx]+' val_acc')\n",
    "    plt.plot(log.history['acc'], '{}.'.format(color[idx]))\n",
    "    plt.plot(log.history['val_acc'], '{}-'.format(color[idx]))\n",
    "\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(label_n, loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "label_n = []\n",
    "for idx, log in enumerate(opt_logger):\n",
    "    label_n.append(opt_name[idx]+' acc')\n",
    "    label_n.append(opt_name[idx]+' val_acc')\n",
    "    plt.plot(log.history['loss'], '{}.'.format(color[idx]))\n",
    "    plt.plot(log.history['val_loss'], '{}-'.format(color[idx]))\n",
    "\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(label_n, loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
